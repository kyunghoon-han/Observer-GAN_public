{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Base.Iterators: partition\n",
    "# Flux stuff\n",
    "using Flux, CUDA\n",
    "using Flux.Losses: logitcrossentropy\n",
    "using Flux.Optimise\n",
    "# Image stuff\n",
    "using Images, ImageIO, ImageMagick\n",
    "# Plots\n",
    "using Plots\n",
    "# Datasets\n",
    "using MLDatasets\n",
    "using Statistics\n",
    "using Parameters\n",
    "# Other stuff\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using ProgressBars\n",
    "import Distributions: Uniform\n",
    "\n",
    "using Suppressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HPARAMS"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@with_kw mutable struct HPARAMS\n",
    "    batch_size::Int = 64\n",
    "    epochs::Int = 50\n",
    "    # feedback frequency\n",
    "    verbose_freq::Int = 100\n",
    "    # learning rate\n",
    "    lr::Float64 = 0.0001\n",
    "    # minimum allowed fraction value\n",
    "    min_frac::Float64 = 0.01\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "...\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8], [9, 2, 1, 1, 6, 1, 4, 6, 5, 7  …  5, 6, 8, 9, 1, 9, 1, 8, 1, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load full training set\n",
    "train_x, train_y = FashionMNIST.traindata()\n",
    "# load full test set\n",
    "test_x,  test_y  = FashionMNIST.testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 60000)Base.ReinterpretArray{Normed{UInt8,8},3,UInt8,Array{UInt8,3}}\n",
      "(60000,)Array{Int64,1}\n",
      "(28, 28, 10000)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "println(size(train_x), typeof(train_x))\n",
    "println(size(train_y), typeof(train_y))\n",
    "println(size(test_x))\n",
    "println(size(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HPARAMS\n",
       "  batch_size: Int64 64\n",
       "  epochs: Int64 50\n",
       "  verbose_freq: Int64 100\n",
       "  lr: Float64 0.0001\n",
       "  min_frac: Float64 0.01\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = HPARAMS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1, 60000)\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: hparams not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: hparams not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[4]:6",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "# normalize the data to -1 to 1\n",
    "image_tensor = reshape(@.(2f0 .* train_x .- 1f0), 28, 28, 1,:);\n",
    "answer_tensor = reshape(train_y/9.0, 60000)\n",
    "println(size(image_tensor))\n",
    "# parition the above tensor to batches\n",
    "data_x = [image_tensor[:, :, :, r] for r in partition(1:60000, hparams.batch_size)];\n",
    "data_y = [answer_tensor[r] for r in partition(1:60000, hparams.batch_size)];\n",
    "println(size(data_x[1]))\n",
    "println(size(data_y))\n",
    "println(data_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function model()\n",
    "    return Chain(\n",
    "        Conv((2,2), 1 => 4; stride=1, pad=2),\n",
    "        x -> leakyrelu.(x, 0.2f0),\n",
    "        Dropout(0.2),\n",
    "        Conv((2,2), 4=>16; stride=1, pad=2),\n",
    "        x -> leakyrelu.(x, 0.2f0),\n",
    "        Dropout(0.2),\n",
    "        Conv((3,3), 16=>8; stride=1, pad=1),\n",
    "        x -> leakyrelu.(x, 0.2f0),\n",
    "        Dropout(0.2),\n",
    "        Conv((3,3), 8=>4; stride=1, pad=1),\n",
    "        x -> leakyrelu.(x,0.2f0),\n",
    "        Dropout(0.2),\n",
    "        Conv((2,2), 4=>1; stride=1, pad=1),\n",
    "        x -> leakyrelu.(x, 0.2f0),\n",
    "        Dropout(0.2),\n",
    "        x -> reshape(x,100,:),\n",
    "        Dense(100,hparams.batch_size),\n",
    "        x -> leakyrelu.(x,0.2f0),\n",
    "        x -> Statistics.mean(x,dims=2),\n",
    "        x -> sigmoid.(x)\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: hparams not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: hparams not defined",
      "",
      "Stacktrace:",
      " [1] model() at ./In[5]:2",
      " [2] top-level scope at In[6]:1",
      " [3] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "a = model()\n",
    "println(a(data_x[1]))\n",
    "println(size(a(data_x[1])))\n",
    "println(logitcrossentropy(a(data_x[1]),data_y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discrete_observation (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function discrete_observation(from_nn,target,hparams)\n",
    "    max_target = maximum(target)\n",
    "    output = round.(from_nn .* max_target) .- max_target*0.5\n",
    "    ratio_positive = length([i for i in output if i>0]) / length(output)\n",
    "    ratio_negative = length([i for i in output if i<0]) / length(output)\n",
    "    \n",
    "    ratio = abs(ratio_positive - ratio_negative)\n",
    "    if abs(ratio) > hparams.min_frac\n",
    "        return ratio\n",
    "    else\n",
    "        return hparams.min_frac\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "criterion (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function criterion(output,target, factor)\n",
    "    return factor * logitcrossentropy(output,target)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_model (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_model(x,y,model, optim, switch, hparams)\n",
    "    ps = Flux.params(model)\n",
    "    a = model(x)\n",
    "    y = reshape(y,size(a))\n",
    "    loss = 0.0\n",
    "\n",
    "    if switch\n",
    "        factor = discrete_observation(a,y,hparams)\n",
    "    else\n",
    "        factor = 1.0\n",
    "    end\n",
    "    \n",
    "    gs = gradient(ps) do\n",
    "        loss = criterion(model(x),y, factor)\n",
    "    end\n",
    "    update!(optim, ps, gs)\n",
    "    \n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test(model, x, y)\n",
    "    x = reshape(@.(2f0 .* x .- 1f0), 28, 28, 1,:)\n",
    "    y = reshape(y ./ 9.0, 10000)\n",
    "    data_in = [x[:, :, :, r] for r in partition(1:10000, hparams.batch_size)];\n",
    "    targets = [y[r] for r in partition(1:10000, hparams.batch_size)];\n",
    "    counter = 0\n",
    "    output = 0.0\n",
    "    for x in data_in\n",
    "        counter += 1\n",
    "        if counter == length(targets)-1\n",
    "            break\n",
    "        end\n",
    "        a = model(x)\n",
    "        ans = reshape(targets[counter],size(a))\n",
    "        output += Flux.mean(criterion(a,ans,1.0))\n",
    "    end\n",
    "    return 100.0 * output / counter\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(; kws...)\n",
    "    hparams = HPARAMS(; kws...)\n",
    "    # models\n",
    "    without_observation = model() |> gpu\n",
    "    with_observation = model() |> gpu\n",
    "    # optimisers\n",
    "    no_o_optim = ADAM(hparams.lr)\n",
    "    o_optim = ADAM(hparams.lr)\n",
    "   for epoch in 1:hparams.epochs\n",
    "        counter = 0\n",
    "        for x in ProgressBar(data_x)\n",
    "            counter = counter + 1 # this will count the entries of data_y\n",
    "            x = cu(x)\n",
    "            y = cu(data_y[counter])\n",
    "            if counter == length(y)-1\n",
    "                break\n",
    "            end\n",
    "            # now pass the data through the networks\n",
    "            without_loss = train_model(x,y,without_observation,no_o_optim,false,hparams)\n",
    "            with_loss = train_model(x,y,with_observation, o_optim,true,hparams)\n",
    "            \n",
    "            train_step = counter + epoch * hparams.epochs\n",
    "            \n",
    "            # test\n",
    "            if train_step % hparams.verbose_freq == 0\n",
    "                without = test(without_observation, cu(test_x),cu(test_y))\n",
    "                with = test(with_observation, cu(test_x),cu(test_y))\n",
    "                println()\n",
    "                println(\"At $(train_step) step.\")\n",
    "                println(\"Without observations, the loss is : \", without_loss)\n",
    "                println(\"With observations, the loss is : \", with_loss)\n",
    "                println(\"Without observations, we have an accuracy of $(without)%\")\n",
    "                println(\"With observations, we have an accuracy of $(with)%\")\n",
    "            end # end of test\n",
    "        end # end of inner for-loop\n",
    "    end # end of epoch for-loop\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0%┣██▏                                        ┫ 47/938 [01:18<25:01, 0.6 it/s]\n",
      "At 100 step.\n",
      "Without observations, the loss is : 142.342041015625\n",
      "With observations, the loss is : 142.33233642578125\n",
      "Without observations, we have an accuracy of 13218.941604785423%\n",
      "With observations, we have an accuracy of 13218.956807501974%\n",
      "5.0%┣██                                        ┫ 47/938 [00:01<00:14, 64.6 it/s]\n",
      "At 200 step.\n",
      "Without observations, the loss is : 142.33795166015625\n",
      "With observations, the loss is : 84.51300477981567\n",
      "Without observations, we have an accuracy of 13218.943495967784%\n",
      "With observations, we have an accuracy of 13218.965083343692%\n",
      "5.1%┣██▏                                       ┫ 48/938 [00:01<00:14, 65.1 it/s]\n",
      "At 300 step.\n",
      "Without observations, the loss is : 142.34579467773438\n",
      "With observations, the loss is : 31.13790225982666\n",
      "Without observations, we have an accuracy of 13218.93797403048%\n",
      "With observations, we have an accuracy of 13218.9958334988%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 64.9 it/s]\n",
      "At 400 step.\n",
      "Without observations, the loss is : 142.3601837158203\n",
      "With observations, the loss is : 26.69169044494629\n",
      "Without observations, we have an accuracy of 13219.121308408225%\n",
      "With observations, we have an accuracy of 13219.22711032069%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:13, 65.9 it/s]\n",
      "At 500 step.\n",
      "Without observations, the loss is : 142.389892578125\n",
      "With observations, the loss is : 31.14278221130371\n",
      "Without observations, we have an accuracy of 13220.248619749334%\n",
      "With observations, we have an accuracy of 13220.012068442813%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 65.0 it/s]\n",
      "At 600 step.\n",
      "Without observations, the loss is : 142.4009552001953\n",
      "With observations, the loss is : 44.49811935424805\n",
      "Without observations, we have an accuracy of 13221.673805387607%\n",
      "With observations, we have an accuracy of 13221.418260203458%\n",
      "5.0%┣██                                        ┫ 47/938 [00:01<00:14, 63.4 it/s]\n",
      "At 700 step.\n",
      "Without observations, the loss is : 142.39102172851562\n",
      "With observations, the loss is : 40.049174308776855\n",
      "Without observations, we have an accuracy of 13222.778419330933%\n",
      "With observations, we have an accuracy of 13222.62770132801%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 65.7 it/s]\n",
      "At 800 step.\n",
      "Without observations, the loss is : 142.38970947265625\n",
      "With observations, the loss is : 40.04997682571411\n",
      "Without observations, we have an accuracy of 13223.688246551748%\n",
      "With observations, we have an accuracy of 13223.457479137298%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 65.8 it/s]\n",
      "At 900 step.\n",
      "Without observations, the loss is : 142.36566162109375\n",
      "With observations, the loss is : 35.600341796875\n",
      "Without observations, we have an accuracy of 13224.429394682584%\n",
      "With observations, we have an accuracy of 13223.877336581549%\n",
      "5.0%┣██                                        ┫ 47/938 [00:01<00:14, 64.0 it/s]\n",
      "At 1000 step.\n",
      "Without observations, the loss is : 142.3702392578125\n",
      "With observations, the loss is : 44.49706554412842\n",
      "Without observations, we have an accuracy of 13225.189413049617%\n",
      "With observations, we have an accuracy of 13224.411513068399%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 65.7 it/s]\n",
      "At 1100 step.\n",
      "Without observations, the loss is : 142.35931396484375\n",
      "With observations, the loss is : 44.499759674072266\n",
      "Without observations, we have an accuracy of 13225.551564061749%\n",
      "With observations, we have an accuracy of 13224.886293764472%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 64.9 it/s]\n",
      "At 1200 step.\n",
      "Without observations, the loss is : 142.3439483642578\n",
      "With observations, the loss is : 48.94569683074951\n",
      "Without observations, we have an accuracy of 13225.911566250008%\n",
      "With observations, we have an accuracy of 13225.136637772594%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:13, 66.0 it/s]\n",
      "At 1300 step.\n",
      "Without observations, the loss is : 142.3408203125\n",
      "With observations, the loss is : 48.939727783203125\n",
      "Without observations, we have an accuracy of 13226.125861861428%\n",
      "With observations, we have an accuracy of 13225.49170994351%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 65.8 it/s]\n",
      "At 1400 step.\n",
      "Without observations, the loss is : 142.34286499023438\n",
      "With observations, the loss is : 48.941526889801025\n",
      "Without observations, we have an accuracy of 13226.308982205865%\n",
      "With observations, we have an accuracy of 13225.805812904306%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 65.8 it/s]\n",
      "At 1500 step.\n",
      "Without observations, the loss is : 142.33328247070312\n",
      "With observations, the loss is : 53.38509178161621\n",
      "Without observations, we have an accuracy of 13226.450933401398%\n",
      "With observations, we have an accuracy of 13226.03698642844%\n",
      "5.1%┣██▏                                       ┫ 48/938 [00:01<00:14, 64.7 it/s]\n",
      "At 1600 step.\n",
      "Without observations, the loss is : 142.3359375\n",
      "With observations, the loss is : 62.28352165222168\n",
      "Without observations, we have an accuracy of 13226.593838865598%\n",
      "With observations, we have an accuracy of 13226.294172659214%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:13, 66.0 it/s]\n",
      "At 1700 step.\n",
      "Without observations, the loss is : 142.33164978027344\n",
      "With observations, the loss is : 66.72192335128784\n",
      "Without observations, we have an accuracy of 13226.682625350095%\n",
      "With observations, we have an accuracy of 13226.331304841571%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:13, 66.0 it/s]\n",
      "At 1800 step.\n",
      "Without observations, the loss is : 142.33245849609375\n",
      "With observations, the loss is : 66.71525001525879\n",
      "Without observations, we have an accuracy of 13226.78442259459%\n",
      "With observations, we have an accuracy of 13226.563432974022%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 65.7 it/s]\n",
      "At 1900 step.\n",
      "Without observations, the loss is : 142.319091796875\n",
      "With observations, the loss is : 71.16119384765625\n",
      "Without observations, we have an accuracy of 13226.824289560309%\n",
      "With observations, we have an accuracy of 13226.652678906752%\n",
      "5.0%┣██                                        ┫ 47/938 [00:01<00:14, 64.9 it/s]\n",
      "At 2000 step.\n",
      "Without observations, the loss is : 142.31964111328125\n",
      "With observations, the loss is : 71.15425872802734\n",
      "Without observations, we have an accuracy of 13226.957441904602%\n",
      "With observations, we have an accuracy of 13226.896978885019%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 65.4 it/s]\n",
      "At 2100 step.\n",
      "Without observations, the loss is : 142.32406616210938\n",
      "With observations, the loss is : 71.15320587158203\n",
      "Without observations, we have an accuracy of 13226.965540596562%\n",
      "With observations, we have an accuracy of 13226.826582352318%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 65.7 it/s]\n",
      "At 2200 step.\n",
      "Without observations, the loss is : 142.3175048828125\n",
      "With observations, the loss is : 71.152587890625\n",
      "Without observations, we have an accuracy of 13227.05364746925%\n",
      "With observations, we have an accuracy of 13226.89980096966%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 65.7 it/s]\n",
      "At 2300 step.\n",
      "Without observations, the loss is : 142.31680297851562\n",
      "With observations, the loss is : 71.15267944335938\n",
      "Without observations, we have an accuracy of 13227.108435787031%\n",
      "With observations, we have an accuracy of 13226.911737912069%\n",
      "5.0%┣██                                        ┫ 47/938 [00:01<00:14, 64.9 it/s]\n",
      "At 2400 step.\n",
      "Without observations, the loss is : 142.311279296875\n",
      "With observations, the loss is : 71.1491928100586\n",
      "Without observations, we have an accuracy of 13227.066297222067%\n",
      "With observations, we have an accuracy of 13227.037398377044%\n",
      "5.2%┣██▏                                       ┫ 49/938 [00:01<00:14, 65.7 it/s]\n",
      "At 2500 step.\n",
      "Without observations, the loss is : 142.309326171875\n",
      "With observations, the loss is : 71.1464614868164\n",
      "Without observations, we have an accuracy of 13227.116199181635%\n",
      "With observations, we have an accuracy of 13227.183990244177%\n",
      "6.6%┣██▊                                       ┫ 62/938 [00:01<00:13, 68.4 it/s]"
     ]
    }
   ],
   "source": [
    "@suppress_err begin\n",
    "    train()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
